# ü¶úüîó LangChain Basic - Developing LLM Applications

![Python Version](https://img.shields.io/badge/python-3.13-blue.svg)
![LangChain](https://img.shields.io/badge/LangChain-1.0.3-green.svg)
![UV](https://img.shields.io/badge/uv-latest-orange.svg)
![Hugging Face](https://img.shields.io/badge/ü§ó_Hugging_Face-transformers-yellow.svg)

Repositorio del curso **"Developing LLM Applications with LangChain"** de DataCamp. Este proyecto contiene ejemplos pr√°cticos y ejercicios que cubren los fundamentos de desarrollo de aplicaciones con Large Language Models (LLMs) utilizando el framework LangChain.

## üìã Tabla de Contenidos

- [Descripci√≥n](#-descripci√≥n)
- [Requisitos Previos](#-requisitos-previos)
- [Instalaci√≥n](#-instalaci√≥n)
- [Configuraci√≥n](#Ô∏è-configuraci√≥n)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Contenido por Cap√≠tulo](#-contenido-por-cap√≠tulo)
  - [Chapter 1: Fundamentos de LLMs y Prompts](#chapter-1-fundamentos-de-llms-y-prompts)
  - [Chapter 2: Chains y Agents](#chapter-2-chains-y-agents)
  - [Chapter 3: RAG y Document Processing](#chapter-3-rag-y-document-processing)
- [Uso](#-uso)
- [Dependencias](#-dependencias)
- [Notas Importantes](#-notas-importantes)

---

## üéØ Descripci√≥n

Este repositorio contiene implementaciones pr√°cticas de conceptos clave en el desarrollo de aplicaciones con LLMs:

- **Prompt Engineering**: Plantillas de prompts, few-shot learning, y chat prompts
- **Chains**: Encadenamiento secuencial de operaciones con LLMs
- **Agents**: Agentes ReAct con herramientas personalizadas
- **RAG (Retrieval Augmented Generation)**: B√∫squeda sem√°ntica y generaci√≥n aumentada
- **Document Processing**: Carga y procesamiento de documentos (PDF, HTML, CSV)
- **Vector Stores**: Almacenamiento y b√∫squeda vectorial con Chroma

---

## üîß Requisitos Previos

- **Python 3.13** o superior (compatible con 3.11+)
- **uv** - Gestor de paquetes y dependencias de Python (escrito en Rust)
- **OpenAI API Key** - Para usar modelos de OpenAI (GPT-4, GPT-3.5)

### Instalaci√≥n de `uv`

```bash
# Linux/macOS
curl -LsSf https://astral.sh/uv/install.sh | sh

# O con pip
pip install uv
```

---

## üì¶ Instalaci√≥n

1. **Clonar el repositorio**

```bash
git clone <tu-repo-url>
cd langchain_basic
```

2. **Crear entorno virtual con Python 3.13**

```bash
# uv crear√° autom√°ticamente el .venv con la versi√≥n especificada en .python-version
uv sync
```

Este comando:

- Lee el archivo `.python-version` (3.13)
- Crea un entorno virtual en `.venv/`
- Instala todas las dependencias del `pyproject.toml`
- Genera/actualiza el `uv.lock` para versiones reproducibles

3. **Instalar dependencias adicionales (requirements.txt)**

```bash
# Algunas dependencias como transformers se instalan por separado
uv pip install -r requirements.txt
```

4. **Verificar la instalaci√≥n**

```bash
# Verificar que el entorno est√© activo
uv run python --version
# Deber√≠a mostrar: Python 3.13.x
```

---

## ‚öôÔ∏è Configuraci√≥n

### 1. Configurar API Key de OpenAI

Crea un archivo `.env` en la ra√≠z del proyecto:

```bash
cp .env.example .env
```

Edita el archivo `.env` y agrega tu API key:

```env
# .env
OPENAI_API_KEY=<your_api_key_goes_here>
```

> ‚ö†Ô∏è **Importante**: Nunca hagas commit del archivo `.env` (ya est√° en `.gitignore`)

### 2. Agregar nuevas dependencias (opcional)

Si necesitas agregar m√°s librer√≠as:

```bash
# Agregar una nueva dependencia
uv add nombre-libreria

# Sincronizar (instalar en .venv)
uv sync
```

---

## üìÅ Estructura del Proyecto

```
langchain_basic/
‚îÇ
‚îú‚îÄ‚îÄ .env                    # Variables de entorno (NO hacer commit)
‚îú‚îÄ‚îÄ .env.example            # Ejemplo de variables de entorno
‚îú‚îÄ‚îÄ .python-version         # Versi√≥n de Python (3.13)
‚îú‚îÄ‚îÄ pyproject.toml          # Configuraci√≥n del proyecto y dependencias
‚îú‚îÄ‚îÄ uv.lock                 # Lock file con versiones exactas
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias instaladas con pip (ver nota)
‚îú‚îÄ‚îÄ README.md               # Este archivo
‚îÇ
‚îú‚îÄ‚îÄ Chapter_1/              # Fundamentos de LLMs y Prompts
‚îÇ   ‚îú‚îÄ‚îÄ open_ai.py          # Uso b√°sico de OpenAI LLM
‚îÇ   ‚îú‚îÄ‚îÄ prompt_template.py  # Plantillas de prompts b√°sicas
‚îÇ   ‚îú‚îÄ‚îÄ chat_prompt.py      # Chat prompts con contexto
‚îÇ   ‚îú‚îÄ‚îÄ few_shoot.py        # Few-shot learning
‚îÇ   ‚îî‚îÄ‚îÄ hugging_face.py     # Uso de modelos de Hugging Face (local)
‚îÇ
‚îú‚îÄ‚îÄ Chapter_2/              # Chains y Agents
‚îÇ   ‚îú‚îÄ‚îÄ sequential_chains.py # Cadenas secuenciales con LCEL
‚îÇ   ‚îú‚îÄ‚îÄ tools_intro.py      # Herramientas personalizadas con m√∫ltiples ejemplos
‚îÇ   ‚îî‚îÄ‚îÄ react_intro.py      # Agentes ReAct con Wikipedia
‚îÇ
‚îî‚îÄ‚îÄ Chapter_3/              # RAG y Document Processing
    ‚îú‚îÄ‚îÄ char_splitter.py            # Text splitting por caracteres
    ‚îú‚îÄ‚îÄ recursive_splitter.py       # Text splitting recursivo
    ‚îú‚îÄ‚îÄ csv_loader.py               # Cargar documentos CSV (con output detallado)
    ‚îú‚îÄ‚îÄ html_loader.py              # Cargar documentos HTML
    ‚îú‚îÄ‚îÄ pdf_loader.py               # Cargar documentos PDF
    ‚îú‚îÄ‚îÄ docs_splitter.py            # Splitting de documentos HTML
    ‚îú‚îÄ‚îÄ rag_intro.py                # RAG completo con Chroma
    ‚îú‚îÄ‚îÄ fifa_countries_audience.csv # Datos de ejemplo (audiencia FIFA)
    ‚îú‚îÄ‚îÄ rag_vs_fine_tuning.pdf      # PDF de ejemplo para RAG
    ‚îî‚îÄ‚îÄ white_house_executive_order_nov_2023.html # Documento HTML de ejemplo
```

---

## üìö Contenido por Cap√≠tulo

### Chapter 1: Fundamentos de LLMs y Prompts

#### 1Ô∏è‚É£ `open_ai.py` - Uso B√°sico de OpenAI

Introducci√≥n al uso de modelos de OpenAI con LangChain.

```python
# Caracter√≠sticas:
- Carga de API key desde .env
- Creaci√≥n de instancia de ChatOpenAI
- Invocaci√≥n simple de prompts
```

**Conceptos**: LLM b√°sico, invocaci√≥n de modelos

---

#### 2Ô∏è‚É£ `prompt_template.py` - Plantillas de Prompts

Uso de plantillas din√°micas para generar prompts reutilizables.

```python
# Caracter√≠sticas:
- PromptTemplate con variables
- Chains con operador LCEL (|)
- Formateo de prompts
```

**Conceptos**: Templates, variables de entrada, LCEL chains

---

#### 3Ô∏è‚É£ `chat_prompt.py` - Chat Prompts

Prompts conversacionales con contexto de sistema, humano y AI.

```python
# Caracter√≠sticas:
- ChatPromptTemplate con m√∫ltiples roles
- Sistema de mensajes (system, human, ai)
- Chains con contexto conversacional
```

**Conceptos**: Chat templates, roles de mensajes, contexto conversacional

---

#### 4Ô∏è‚É£ `few_shoot.py` - Few-Shot Learning

Aprendizaje con ejemplos para guiar las respuestas del LLM.

```python
# Caracter√≠sticas:
- FewShotPromptTemplate
- Lista de ejemplos estructurados
- Formateo de ejemplos
```

**Conceptos**: Few-shot learning, prompt engineering, ejemplos estructurados

---

#### 5Ô∏è‚É£ `hugging_face.py` - Modelos de Hugging Face

Uso de modelos open-source desde Hugging Face Hub ejecutados **localmente**.

```python
# Caracter√≠sticas:
- HuggingFacePipeline para modelos locales
- Modelo ligero: crumb/nano-mistral
- Configuraci√≥n de par√°metros de generaci√≥n (max_new_tokens)
- Sin necesidad de API key (ejecuci√≥n local)
```

**Conceptos**: Modelos open-source, Hugging Face, pipelines locales, inferencia sin API

**Dependencias requeridas**: `langchain-huggingface`, `transformers`

---

### Chapter 2: Chains y Agents

#### 1Ô∏è‚É£ `sequential_chains.py` - Cadenas Secuenciales

Encadenamiento de m√∫ltiples prompts de forma secuencial.

```python
# Caracter√≠sticas:
- LCEL (LangChain Expression Language)
- M√∫ltiples prompts encadenados
- StrOutputParser para parsear salidas
- Paso de variables entre etapas
```

**Conceptos**: Sequential chains, LCEL, output parsers, composici√≥n de prompts

---

#### 2Ô∏è‚É£ `tools_intro.py` - Herramientas Personalizadas

Creaci√≥n de herramientas personalizadas para agentes con m√∫ltiples ejemplos de uso.

```python
# Caracter√≠sticas:
- Decorador @tool para definir herramientas
- Funciones Python como herramientas para agentes
- Integraci√≥n con pandas DataFrames
- PromptTemplate para formatear queries
- M√∫ltiples invocaciones de ejemplo (Tech Innovations LLC, Peak Performance Co.)
```

**Conceptos**: Custom tools, function calling, agentes con datos externos, reutilizaci√≥n de prompts

---

#### 3Ô∏è‚É£ `react_intro.py` - Agentes ReAct

Agentes que razonan y act√∫an con herramientas externas.

```python
# Caracter√≠sticas:
- create_agent (ReAct pattern)
- Wikipedia tool para b√∫squeda de informaci√≥n
- HumanMessage para invocaci√≥n idiom√°tica de LangChain
- Par√°metros de reproducibilidad (temperature=0.1, seed=42)
- Razonamiento paso a paso
```

**Conceptos**: ReAct agents, tool usage, reasoning & acting, Wikipedia integration, reproducibilidad

---

### Chapter 3: RAG y Document Processing

#### 1Ô∏è‚É£ `char_splitter.py` - Character Text Splitter

Splitting de texto por n√∫mero de caracteres.

```python
# Caracter√≠sticas:
- CharacterTextSplitter
- Control de chunk_size y chunk_overlap
- Separadores personalizados
```

**Conceptos**: Text splitting, chunks, overlap

---

#### 2Ô∏è‚É£ `recursive_splitter.py` - Recursive Character Splitter

Splitting recursivo con jerarqu√≠a de separadores.

```python
# Caracter√≠sticas:
- RecursiveCharacterTextSplitter
- Jerarqu√≠a de separadores ["\n\n", "\n", " ", ""]
- Preservaci√≥n de contexto sem√°ntico
```

**Conceptos**: Recursive splitting, semantic chunking, separator hierarchy

---

#### 3Ô∏è‚É£ `csv_loader.py` - CSV Document Loader

Carga de datos estructurados desde archivos CSV con output detallado.

```python
# Caracter√≠sticas:
- CSVLoader para archivos tabulares
- Rutas absolutas con Path(__file__) para ejecuci√≥n independiente
- Output formateado mostrando las primeras 3 filas
- Visualizaci√≥n de content y metadata separados
```

**Conceptos**: Document loaders, structured data, file loading, metadata extraction

**Datos**: `fifa_countries_audience.csv` - Datos de audiencia de pa√≠ses FIFA

---

#### 4Ô∏è‚É£ `html_loader.py` - HTML Document Loader

Carga y parsing de documentos HTML.

```python
# Caracter√≠sticas:
- UnstructuredHTMLLoader
- Extracci√≥n de texto de HTML
- Metadata de documentos
```

**Conceptos**: HTML parsing, unstructured data, metadata extraction

**Datos**: `white_house_executive_order_nov_2023.html` - Orden Ejecutiva de IA

---

#### 5Ô∏è‚É£ `pdf_loader.py` - PDF Document Loader

Carga de documentos PDF con metadata.

```python
# Caracter√≠sticas:
- PyPDFLoader
- Extracci√≥n de texto por p√°ginas
- Metadata (p√°gina, fuente)
```

**Conceptos**: PDF processing, page extraction, document metadata

---

#### 6Ô∏è‚É£ `docs_splitter.py` - Document Splitting

Splitting de documentos HTML cargados con separadores optimizados.

```python
# Caracter√≠sticas:
- Carga de HTML con UnstructuredHTMLLoader
- RecursiveCharacterTextSplitter en documentos
- Jerarqu√≠a de separadores optimizada: ['\n\n', '\n', '. ', '.', ' ', '']
- Output formateado con longitud de cada chunk
- Visualizaci√≥n del primer chunk como ejemplo
```

**Conceptos**: Document processing pipeline, splitting loaded documents, separator optimization

---

#### 7Ô∏è‚É£ `rag_intro.py` - RAG Completo (‚òÖ)

**Pipeline completo de Retrieval Augmented Generation.**

```python
# Caracter√≠sticas:
- Carga de PDF (PyPDFLoader) - rag_vs_fine_tuning.pdf
- Splitting de documentos (RecursiveCharacterTextSplitter)
- Embeddings con OpenAI (text-embedding-3-small)
- Vector store con Chroma (persistente en directorio actual)
- Retriever con similarity search (k=3 documentos)
- RAG chain con LCEL
- RunnablePassthrough para pasar la pregunta directamente
- Generaci√≥n de respuestas contextualizadas
```

**Pipeline RAG**:

```
1. Load PDF ‚Üí 2. Split Text ‚Üí 3. Create Embeddings ‚Üí 
4. Store in Vector DB ‚Üí 5. Retrieve Relevant Chunks ‚Üí 
6. Generate Answer with Context
```

**Conceptos**: RAG, embeddings, vector stores, Chroma, similarity search, retrieval chains, RunnablePassthrough

**Datos**: `rag_vs_fine_tuning.pdf` - Paper comparando RAG vs Fine-tuning

---

## üöÄ Uso

### Ejecutar Scripts

Gracias a las rutas absolutas implementadas, puedes ejecutar los scripts desde **cualquier ubicaci√≥n**:

```bash
# Desde la ra√≠z del proyecto
uv run Chapter_1/open_ai.py
uv run Chapter_2/sequential_chains.py
uv run Chapter_3/rag_intro.py

# Desde dentro de un cap√≠tulo
cd Chapter_3
uv run csv_loader.py

# Desde cualquier otra ubicaci√≥n
uv run /ruta/completa/Chapter_1/chat_prompt.py
```

### Ejemplos de Uso por Cap√≠tulo

**Chapter 1 - Prompts b√°sicos**

```bash
# Probar diferentes proveedores de LLMs
uv run Chapter_1/open_ai.py
uv run Chapter_1/hugging_face.py

# Experimentar con templates
uv run Chapter_1/prompt_template.py
uv run Chapter_1/chat_prompt.py
uv run Chapter_1/few_shoot.py
```

**Chapter 2 - Chains y Agents**

```bash
# Cadenas secuenciales
uv run Chapter_2/sequential_chains.py

# Agentes con herramientas
uv run Chapter_2/tools_intro.py
uv run Chapter_2/react_intro.py
```

**Chapter 3 - RAG y Documents**

```bash
# Document loaders
uv run Chapter_3/csv_loader.py
uv run Chapter_3/html_loader.py
uv run Chapter_3/pdf_loader.py

# Text splitters
uv run Chapter_3/char_splitter.py
uv run Chapter_3/recursive_splitter.py
uv run Chapter_3/docs_splitter.py

# RAG completo
uv run Chapter_3/rag_intro.py
```

---

## üì¶ Dependencias

### Dependencias Principales

```toml
dependencies = [
    "langchain>=1.0.3",              # Framework principal
    "langchain-chroma>=1.0.0",       # Vector store con Chroma
    "langchain-community>=0.4.1",    # Loaders y tools comunitarios
    "langchain-huggingface>=1.2.0",  # Integraci√≥n con Hugging Face
    "langchain-openai>=1.0.1",       # Integraci√≥n con OpenAI
    "pandas>=2.3.3",                 # Manipulaci√≥n de datos
    "pypdf>=6.1.3",                  # Procesamiento de PDFs
    "python-dotenv>=1.2.1",          # Manejo de variables de entorno
    "transformers>=4.57.3",          # Modelos de Hugging Face (PyTorch)
    "unstructured>=0.18.15",         # Procesamiento de docs no estructurados
    "wikipedia>=1.4.0",              # API de Wikipedia para agentes
]
```

### Gesti√≥n de Dependencias con `uv`

```bash
# Ver dependencias instaladas
uv pip list

# Agregar nueva dependencia
uv add nombre-paquete

# Instalar todas las dependencias del proyecto
uv sync

# Actualizar dependencias
uv lock --upgrade
```

---

## üìù Notas Importantes

### Sobre `uv`

- **uv** es un gestor de paquetes de Python escrito en Rust, extremadamente r√°pido
- Reemplaza `pip`, `pip-tools`, `virtualenv` y `poetry` en uno solo
- `uv sync` instala las dependencias **f√≠sicamente** en `.venv/lib/python3.13/site-packages/`
- El `uv.lock` garantiza builds reproducibles (como `package-lock.json` en npm)

### Flujo de Trabajo con `uv`

1. **Agregar dependencia**: `uv add <paquete>` ‚Üí Actualiza `pyproject.toml`
2. **Sincronizar**: `uv sync` ‚Üí Instala en `.venv/`
3. **Ejecutar**: `uv run <script.py>` ‚Üí Ejecuta con el entorno correcto

### `uv add` vs `uv pip install`

‚ö†Ô∏è **Importante**: Existen dos formas de instalar paquetes con `uv`:

| Comando | Comportamiento | Persistencia |
|---------|----------------|---------------|
| `uv add <paquete>` | Agrega al `pyproject.toml` y al `uv.lock` | ‚úÖ Persiste con `uv sync` |
| `uv pip install <paquete>` | Instala directamente en `.venv` | ‚ùå Se borra con `uv sync` |

**En este proyecto**:
- La mayor√≠a de dependencias est√°n en `pyproject.toml` (instaladas con `uv add`)
- `transformers` y sus dependencias est√°n en `requirements.txt` (instaladas con `uv pip install`)

**¬øPor qu√©?** Algunas librer√≠as como `transformers` pueden tener conflictos de resoluci√≥n de dependencias con `uv add`. En esos casos, se instalan con `uv pip install` y se documentan en `requirements.txt`.

**Para instalar todo el proyecto**:
```bash
# 1. Instalar dependencias del pyproject.toml
uv sync

# 2. Instalar dependencias adicionales del requirements.txt
uv pip install -r requirements.txt
```

### Rutas Absolutas

Todos los scripts que cargan archivos usan rutas absolutas:

```python
from pathlib import Path

# Obtener directorio del script
script_dir = Path(__file__).parent

# Construir ruta al archivo
file_path = script_dir / "archivo.csv"
```

Esto permite ejecutar scripts desde cualquier ubicaci√≥n sin errores de ruta.

### Variables de Entorno

- El archivo `.env` **NO** debe hacer commit (ya est√° en `.gitignore`)
- Usa `.env.example` como plantilla
- Siempre usa `python-dotenv` para cargar variables:

```python
from dotenv import load_dotenv
import os

load_dotenv()
API_KEY = os.getenv('OPENAI_API_KEY')
```

### Vector Store Persistente

El script `rag_intro.py` genera archivos de base de datos de Chroma:

- `chroma.sqlite3`
- Carpeta `b5...cf8/` (O algo similar, relacionado con el ID del vector store)

Estos archivos est√°n en `.gitignore` y se regeneran autom√°ticamente.

---

## üéì Recursos Adicionales

- [Documentaci√≥n de LangChain](https://python.langchain.com/)
- [UV Documentation](https://github.com/astral-sh/uv)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [DataCamp Course](https://www.datacamp.com/courses/developing-llm-applications-with-langchain)

---

## üìÑ Licencia

Este proyecto es material educativo del curso de DataCamp "Developing LLM Applications with LangChain".

---

## ü§ù Contribuciones

Este es un repositorio de aprendizaje personal. Si encuentras errores o mejoras, si√©ntete libre de abrir un issue.

---

**Desarrollado con ‚ù§Ô∏è usando LangChain y UV**
